project: average-reward-drl
group: ${algo.name}-${env.name}
tags:
- ${algo.name}
- ${env.name}
seed: 0
total_steps: 1000000
eval_episodes: 10
eval_interval: 5000
log_interval: 500
use_reset_scheme: ${algo.use_reset_scheme}
algo:
  id: RVI_SAC
  name: ${algo.id}
  params:
    batch_size: 256
    lr: 0.0003
    critic_hidden_dim: 256
    actor_hidden_dim: 256
    replay_buffer_capacity: 1000000
    replay_start_size: 10000
    tau: 0.005
    critic_reset_hidden_dim: 64
    fq_gain: 1.0
    fq_reset_gain: 1.0
    fq_update_tau: 0.005
    target_reset_prob: 0.001
  use_reset_scheme: true
env:
  type: gymnasium
  id: Ant-v4
  name: ${env.id}
  has_termination: true
  train:
    max_episode_steps: 1000
  eval:
    max_episode_steps: 1000
  reference_state:
  - 0.4658
  - 0.3983
  - 0.7825
  - -0.4744
  - -0.0632
  - 0.0132
  - 0.6156
  - -0.5388
  - -1.0077
  - -0.3787
  - -0.7913
  - 0.1345
  - 1.1419
  - -1.3971
  - -0.2002
  - -0.4032
  - 4.1411
  - 0.1198
  - 1.7136
  - -11.2308
  - -0.7422
  - -0.7605
  - -2.4134
  - -4.8597
  - 4.593
  - 3.8711
  - 0.6545
  reference_action:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
